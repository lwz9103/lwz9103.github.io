<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>lwz9103 的砖厂</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://lwz9103.github.io/"/>
  <updated>2021-03-22T11:33:02.975Z</updated>
  <id>https://lwz9103.github.io/</id>
  
  <author>
    <name>lwz9103</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>mlsql-task-5</title>
    <link href="https://lwz9103.github.io/2021/03/22/mlsql-task-5/"/>
    <id>https://lwz9103.github.io/2021/03/22/mlsql-task-5/</id>
    <published>2021-03-22T11:26:36.000Z</published>
    <updated>2021-03-22T11:33:02.975Z</updated>
    
    <content type="html"><![CDATA[<h3 id="学习和开发-ET-插件"><a href="#学习和开发-ET-插件" class="headerlink" title="学习和开发 ET 插件"></a>学习和开发 ET 插件</h3><ol><li><p>在 <code>/mlsql/external/mlsql-ets/src/main/java/tech/mlsql/plugins/ets</code> 目录下新增 ET 插件类 <code>KylinSource</code></p></li><li><p>编写 <code>KylinSource</code></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> tech.mlsql.plugins.ets</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.ml.util.<span class="type">Identifiable</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.&#123;<span class="type">DataFrame</span>, <span class="type">SparkSession</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.expressions.<span class="type">UserDefinedFunction</span></span><br><span class="line"><span class="keyword">import</span> streaming.dsl.mmlib.<span class="type">SQLAlg</span></span><br><span class="line"><span class="keyword">import</span> streaming.dsl.mmlib.algs.param.<span class="type">WowParams</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">KylinSource</span>(<span class="params">override val uid: <span class="type">String</span></span>) <span class="keyword">extends</span> <span class="title">SQLAlg</span> <span class="keyword">with</span> <span class="title">WowParams</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">this</span></span>() = <span class="keyword">this</span>(<span class="type">Identifiable</span>.randomUID(<span class="string">"tech.mlsql.plugins.ets.KylinSource"</span>))</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">train</span></span>(df: <span class="type">DataFrame</span>, path: <span class="type">String</span>, params: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">String</span>]): <span class="type">DataFrame</span> = &#123;</span><br><span class="line">    df.sparkSession.read</span><br><span class="line">      .format(<span class="string">"jdbc"</span>)</span><br><span class="line">      .option(<span class="string">"url"</span>, <span class="string">s"jdbc:kylin://<span class="subst">$&#123;params("host")&#125;</span>:<span class="subst">$&#123;params("port")&#125;</span>/<span class="subst">$&#123;params("project")&#125;</span>"</span>)</span><br><span class="line">      .option(<span class="string">"driver"</span>, <span class="string">"org.apache.kylin.jdbc.Driver"</span>)</span><br><span class="line">      .option(<span class="string">"user"</span>, params(<span class="string">"user"</span>))</span><br><span class="line">      .option(<span class="string">"password"</span>, params(<span class="string">"password"</span>))</span><br><span class="line">      .option(<span class="string">"query"</span>, params(<span class="string">"query"</span>)).load()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">batchPredict</span></span>(df: <span class="type">DataFrame</span>, path: <span class="type">String</span>, params: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">String</span>]): <span class="type">DataFrame</span> = train(df, path, params)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">load</span></span>(sparkSession: <span class="type">SparkSession</span>, path: <span class="type">String</span>, params: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">String</span>]): <span class="type">Any</span> = ???</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">predict</span></span>(sparkSession: <span class="type">SparkSession</span>, _model: <span class="type">Any</span>, name: <span class="type">String</span>, params: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">String</span>]): <span class="type">UserDefinedFunction</span> = ???</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>修改 <code>tech.mlsql.plugins.ets.ETApp</code> 注册内置插件，新增一行</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">ETRegister</span>.register(<span class="string">"Kylin"</span>, classOf[<span class="type">KylinSource</span>].getName)</span><br></pre></td></tr></table></figure></li><li><p>在 <code>streamingpro-mlsql/pom.xml</code> 中新增 kylin jdbc driver 依赖</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.apache.kylin&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;kylin-jdbc&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;3.0.0&lt;/version&gt;</span><br><span class="line">    &lt;scope&gt;provided&lt;/scope&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure></li><li><p>启动勾选包含 Provided 的依赖</p><p><img src="//lwz9103.github.io/2021/03/22/mlsql-task-5/image-20210322193150737.png" alt="image-20210322193150737"></p></li><li><p>在简易控制台测试代码</p><p><img src="//lwz9103.github.io/2021/03/22/mlsql-task-5/image-20210322193248369.png" alt="image-20210322193248369"></p></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;学习和开发-ET-插件&quot;&gt;&lt;a href=&quot;#学习和开发-ET-插件&quot; class=&quot;headerlink&quot; title=&quot;学习和开发 ET 插件&quot;&gt;&lt;/a&gt;学习和开发 ET 插件&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;在 &lt;code&gt;/mlsql/external/m
      
    
    </summary>
    
      <category term="MLSQL" scheme="https://lwz9103.github.io/categories/MLSQL/"/>
    
      <category term="MLSQL 入门学习任务" scheme="https://lwz9103.github.io/categories/MLSQL/MLSQL-%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E4%BB%BB%E5%8A%A1/"/>
    
    
  </entry>
  
  <entry>
    <title>mlsql-task-4</title>
    <link href="https://lwz9103.github.io/2021/03/22/mlsql-task-4/"/>
    <id>https://lwz9103.github.io/2021/03/22/mlsql-task-4/</id>
    <published>2021-03-22T10:18:53.000Z</published>
    <updated>2021-03-22T10:33:53.831Z</updated>
    
    <content type="html"><![CDATA[<h3 id="编写脚本打包发布MLSQL引擎"><a href="#编写脚本打包发布MLSQL引擎" class="headerlink" title="编写脚本打包发布MLSQL引擎"></a>编写脚本打包发布MLSQL引擎</h3><ol><li><p>在工程根目录下创建 package.sh，并赋予执行权限 <code>chmod +x package.sh</code></p><p><img src="//lwz9103.github.io/2021/03/22/mlsql-task-4/image-20210322182312221.png" alt="image-20210322182312221"></p><p>编写脚本如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line">#!/usr/bin/env bash</span><br><span class="line"></span><br><span class="line">export LC_ALL=zh_CN.UTF-8</span><br><span class="line">export LANG=zh_CN.UTF-8</span><br><span class="line"># 依赖的Spark版本</span><br><span class="line">export MLSQL_SPARK_VERSION=2.4</span><br><span class="line"># scala版本</span><br><span class="line">export SCALA_VERSION=2.11</span><br><span class="line"># 项目根目录</span><br><span class="line">export MLSQL_M_HOME=./</span><br><span class="line"># 版本号，保持和maven一致</span><br><span class="line">export VERSION=&quot;2.1.0-SNAPSHOT&quot;</span><br><span class="line"># 构建</span><br><span class="line">export TEMP_DIR=tmp/mlsql-engine_$&#123;MLSQL_SPARK_VERSION&#125;-$&#123;VERSION&#125;</span><br><span class="line">export UPLOAD=false</span><br><span class="line">export ENABLE_CHINESE_ANALYZER=false</span><br><span class="line">./dev/package.sh</span><br><span class="line"></span><br><span class="line"># 在tmp目录生成发行包</span><br><span class="line">rm -rf $&#123;TEMP_DIR&#125;</span><br><span class="line">mkdir -p $&#123;TEMP_DIR&#125;/libs</span><br><span class="line">cp streamingpro-mlsql/target/streamingpro-mlsql-spark_$&#123;MLSQL_SPARK_VERSION&#125;_$&#123;SCALA_VERSION&#125;-$&#123;VERSION&#125;.jar $&#123;TEMP_DIR&#125;/libs</span><br><span class="line"></span><br><span class="line">if [[ &quot;$&#123;ENABLE_CHINESE_ANALYZER&#125;&quot; == &quot;true&quot; ]]; then</span><br><span class="line">  echo &quot;cp -r lib/*.jar $&#123;TEMP_DIR&#125;/libs/&quot;</span><br><span class="line">  cp -r lib/*.jar $&#123;TEMP_DIR&#125;/libs/</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">## 生成启动脚本等</span><br><span class="line">cp dev/start-local.sh $&#123;TEMP_DIR&#125;</span><br><span class="line"></span><br><span class="line">cat &lt;&lt; EOF &gt; &quot;$&#123;TEMP_DIR&#125;/start-default.sh&quot;</span><br><span class="line">if [[ -z &quot;\$&#123;SPARK_HOME&#125;&quot; ]]; then</span><br><span class="line">    echo &quot;===SPARK_HOME is required===&quot;</span><br><span class="line">    exit 1</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">SELF=\$(cd \$(dirname \$0) &amp;&amp; pwd)</span><br><span class="line">cd \$SELF</span><br><span class="line"></span><br><span class="line">./start-local.sh</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &lt;&lt; EOF &gt; &quot;$&#123;TEMP_DIR&#125;/README.md&quot;</span><br><span class="line">1. Configure env SPARK_HOME</span><br><span class="line">2. Run ./start-default.sh</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">chmod u+x  $&#123;TEMP_DIR&#125;/*.sh</span><br><span class="line"></span><br><span class="line">cd $&#123;TEMP_DIR&#125; &amp;&amp; cd ..</span><br><span class="line">tar czvf mlsql-engine_$&#123;MLSQL_SPARK_VERSION&#125;-$&#123;VERSION&#125;.tar.gz mlsql-engine_$&#123;MLSQL_SPARK_VERSION&#125;-$&#123;VERSION&#125;</span><br></pre></td></tr></table></figure></li><li><p>在根目录下执行脚本, <code>./package.sh</code>，在 tmp 目录找到发行包</p><p><img src="//lwz9103.github.io/2021/03/22/mlsql-task-4/image-20210322182600449.png" alt="image-20210322182600449"></p></li><li><p>设置 SPARK_HOME 并启动 MLSQL Engine</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export SPARK_HOME=/Users/wenzheng.liu/devApps/spark-2.4.4-bin-hadoop2.7 &amp;&amp; ./start-default.sh</span><br></pre></td></tr></table></figure><p><img src="//lwz9103.github.io/2021/03/22/mlsql-task-4/image-20210322183027998.png" alt="image-20210322183027998"></p><p><img src="//lwz9103.github.io/2021/03/22/mlsql-task-4/image-20210322183304760.png" alt="image-20210322183304760"></p></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;编写脚本打包发布MLSQL引擎&quot;&gt;&lt;a href=&quot;#编写脚本打包发布MLSQL引擎&quot; class=&quot;headerlink&quot; title=&quot;编写脚本打包发布MLSQL引擎&quot;&gt;&lt;/a&gt;编写脚本打包发布MLSQL引擎&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;在工程根目录下创建
      
    
    </summary>
    
      <category term="MLSQL" scheme="https://lwz9103.github.io/categories/MLSQL/"/>
    
      <category term="MLSQL 入门学习任务" scheme="https://lwz9103.github.io/categories/MLSQL/MLSQL-%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E4%BB%BB%E5%8A%A1/"/>
    
    
  </entry>
  
  <entry>
    <title>mlsql-task-1</title>
    <link href="https://lwz9103.github.io/2021/03/22/mlsql-task-1/"/>
    <id>https://lwz9103.github.io/2021/03/22/mlsql-task-1/</id>
    <published>2021-03-22T09:19:19.000Z</published>
    <updated>2021-03-22T09:55:35.109Z</updated>
    
    <content type="html"><![CDATA[<h3 id="设置-MLSQL-开发环境"><a href="#设置-MLSQL-开发环境" class="headerlink" title="设置 MLSQL 开发环境"></a>设置 MLSQL 开发环境</h3><ol><li><p>设置 MLSQL Engine 开发环境</p><p>将 MLSQL Engine 项目代码用 IDE 导入，然后设置好 Maven Profile，如下勾选<br><img src="//lwz9103.github.io/2021/03/22/mlsql-task-1/image-20210322172950035.png" alt="image-20210322172950035"></p><p>创建调试启动类，参考如下：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> streaming.core</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 2019-03-20 WilliamZhu(allwefantasy@gmail.com)</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">WilliamLocalSparkServiceApp</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="type">StreamingApp</span>.main(<span class="type">Array</span>(</span><br><span class="line">      <span class="string">"-streaming.master"</span>, <span class="string">"local[*]"</span>,</span><br><span class="line">      <span class="string">"-streaming.name"</span>, <span class="string">"god"</span>,</span><br><span class="line">      <span class="string">"-streaming.rest"</span>, <span class="string">"true"</span>,</span><br><span class="line">      <span class="string">"-streaming.thrift"</span>, <span class="string">"false"</span>,</span><br><span class="line">      <span class="string">"-streaming.platform"</span>, <span class="string">"spark"</span>,</span><br><span class="line">      <span class="string">"-spark.mlsql.enable.runtime.directQuery.auth"</span>, <span class="string">"true"</span>,</span><br><span class="line"><span class="comment">//      "-streaming.ps.cluster.enable","false",</span></span><br><span class="line">      <span class="string">"-streaming.enableHiveSupport"</span>,<span class="string">"false"</span>,</span><br><span class="line">      <span class="string">"-spark.mlsql.datalake.overwrite.hive"</span>, <span class="string">"true"</span>,</span><br><span class="line">      <span class="string">"-spark.mlsql.auth.access_token"</span>, <span class="string">"mlsql"</span>,</span><br><span class="line">      <span class="comment">//"-spark.mlsql.enable.max.result.limit", "true",</span></span><br><span class="line">      <span class="comment">//"-spark.mlsql.restful.api.max.result.size", "7",</span></span><br><span class="line">      <span class="comment">//      "-spark.mlsql.enable.datasource.rewrite", "true",</span></span><br><span class="line">      <span class="comment">//      "-spark.mlsql.datasource.rewrite.implClass", "streaming.core.datasource.impl.TestRewrite",</span></span><br><span class="line">      <span class="comment">//"-streaming.job.file.path", "classpath:///test/init.json",</span></span><br><span class="line">      <span class="string">"-streaming.spark.service"</span>, <span class="string">"true"</span>,</span><br><span class="line">      <span class="string">"-streaming.job.cancel"</span>, <span class="string">"true"</span>,</span><br><span class="line">      <span class="string">"-streaming.datalake.path"</span>, <span class="string">"/data/mlsql/datalake"</span>,</span><br><span class="line"></span><br><span class="line">      <span class="string">"-streaming.plugin.clzznames"</span>,<span class="string">"tech.mlsql.plugins.ds.MLSQLExcelApp"</span>,</span><br><span class="line"></span><br><span class="line">      <span class="comment">// scheduler</span></span><br><span class="line">      <span class="string">"-streaming.workAs.schedulerService"</span>, <span class="string">"false"</span>,</span><br><span class="line">      <span class="string">"-streaming.workAs.schedulerService.consoleUrl"</span>, <span class="string">"http://127.0.0.1:9002"</span>,</span><br><span class="line">      <span class="string">"-streaming.workAs.schedulerService.consoleToken"</span>, <span class="string">"mlsql"</span>,</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">//      "-spark.sql.hive.thriftServer.singleSession", "true",</span></span><br><span class="line">      <span class="string">"-streaming.rest.intercept.clzz"</span>, <span class="string">"streaming.rest.ExampleRestInterceptor"</span>,</span><br><span class="line"><span class="comment">//      "-streaming.deploy.rest.api", "true",</span></span><br><span class="line">      <span class="string">"-spark.driver.maxResultSize"</span>, <span class="string">"2g"</span>,</span><br><span class="line">      <span class="string">"-spark.serializer"</span>, <span class="string">"org.apache.spark.serializer.KryoSerializer"</span>,</span><br><span class="line"><span class="comment">//      "-spark.sql.codegen.wholeStage", "true",</span></span><br><span class="line">      <span class="string">"-spark.ui.allowFramingFrom"</span>,<span class="string">"*"</span>,</span><br><span class="line">      <span class="string">"-spark.kryoserializer.buffer.max"</span>, <span class="string">"2000m"</span>,</span><br><span class="line">      <span class="string">"-streaming.driver.port"</span>, <span class="string">"9003"</span></span><br><span class="line"><span class="comment">//      "-spark.files.maxPartitionBytes", "10485760"</span></span><br><span class="line"></span><br><span class="line">      <span class="comment">//meta store</span></span><br><span class="line"><span class="comment">//      "-streaming.metastore.db.type", "mysql",</span></span><br><span class="line"><span class="comment">//      "-streaming.metastore.db.name", "app_runtime_full",</span></span><br><span class="line"><span class="comment">//      "-streaming.metastore.db.config.path", "./__mlsql__/db.yml"</span></span><br><span class="line"></span><br><span class="line">      <span class="comment">//      "-spark.sql.shuffle.partitions", "1",</span></span><br><span class="line">      <span class="comment">//      "-spark.hadoop.mapreduce.job.run-local", "true"</span></span><br><span class="line"></span><br><span class="line">      <span class="comment">//"-streaming.sql.out.path","file:///tmp/test/pdate=20160809"</span></span><br><span class="line"></span><br><span class="line">      <span class="comment">//"-streaming.jobs","idf-compute"  </span></span><br><span class="line">      <span class="comment">//"-streaming.driver.port", "9005"</span></span><br><span class="line">      <span class="comment">//"-streaming.zk.servers", "127.0.0.1",</span></span><br><span class="line">      <span class="comment">//"-streaming.zk.conf_root_dir", "/streamingpro/jack"</span></span><br><span class="line">    ))</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>这里需要注意下 streaming.datalake.path，由于本地调试使用的是本地文件系统，需要保证当前用户有权限在此目录下创建文件/目录</p></blockquote></li><li><p>创建 MLSQL Console 元数据库</p><p>如果没有 mysql 环境，可以用 docker 启动一个</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">docker pull mysql:5.7</span><br><span class="line"><span class="meta">#</span> 设置数据/日志/配置挂载目录</span><br><span class="line">mkdir -p ~/mysql/data ~/mysql/logs ~/mysql/conf</span><br><span class="line">docker run -p 3306:3306 --name mysql -v ~/mysql/conf:/etc/mysql/conf.d -v ~/mysql/logs:/logs -v ~/mysql/data:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=root -d mysql:5.7</span><br></pre></td></tr></table></figure><p>将 MLSQL Console 代码中的表结构导入 mysql 中</p><p><img src="//lwz9103.github.io/2021/03/22/mlsql-task-1/image-20210322174840961.png" alt="image-20210322174840961"></p><p><img src="//lwz9103.github.io/2021/03/22/mlsql-task-1/image-20210322174916532.png" alt="image-20210322174916532"></p></li><li><p>设置 MLSQL Console 开发环境</p><p>在 IDE 导入代码后，直接运行 <code>tech.mlsql.MLSQLConsole</code>, 如果遇到配置文件读取不到的问题，可尝试手动设置 Working directory</p><p><img src="//lwz9103.github.io/2021/03/22/mlsql-task-1/image-20210322173828953.png" alt="image-20210322173828953"></p><p>另外如果启动后，发现无法连通 MLSQL Engine 可在界面手动配置 Engine 的 url</p><p><img src="//lwz9103.github.io/2021/03/22/mlsql-task-1/image-20210322174316404.png" alt="image-20210322174316404"></p></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;设置-MLSQL-开发环境&quot;&gt;&lt;a href=&quot;#设置-MLSQL-开发环境&quot; class=&quot;headerlink&quot; title=&quot;设置 MLSQL 开发环境&quot;&gt;&lt;/a&gt;设置 MLSQL 开发环境&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;设置 MLSQL Engine 开
      
    
    </summary>
    
      <category term="MLSQL" scheme="https://lwz9103.github.io/categories/MLSQL/"/>
    
      <category term="MLSQL 入门学习任务" scheme="https://lwz9103.github.io/categories/MLSQL/MLSQL-%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E4%BB%BB%E5%8A%A1/"/>
    
    
  </entry>
  
  <entry>
    <title>mlsql-task-2</title>
    <link href="https://lwz9103.github.io/2021/03/22/mlsql-task-2/"/>
    <id>https://lwz9103.github.io/2021/03/22/mlsql-task-2/</id>
    <published>2021-03-22T07:07:02.000Z</published>
    <updated>2021-03-22T07:14:53.925Z</updated>
    
    <content type="html"><![CDATA[<h3 id="任务2：学习-MLSQL-基本语言"><a href="#任务2：学习-MLSQL-基本语言" class="headerlink" title="任务2：学习 MLSQL 基本语言"></a>任务2：学习 MLSQL 基本语言</h3><ol><li><p>连接console依赖的数据库中的任意一个表，将数据写到delta lake中，并且查询100条展示出来。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">load</span> jdbc.<span class="string">`mlsql_job`</span> <span class="keyword">where</span> <span class="keyword">url</span>=<span class="string">"jdbc:mysql://localhost:3306/mlsql_console?characterEncoding=utf8&amp;zeroDateTimeBehavior=convertToNull&amp;tinyInt1isBit=false"</span></span><br><span class="line"><span class="keyword">and</span> driver=<span class="string">"com.mysql.jdbc.Driver"</span></span><br><span class="line"><span class="keyword">and</span> <span class="keyword">user</span>=<span class="string">"root"</span></span><br><span class="line"><span class="keyword">and</span> <span class="keyword">password</span>=<span class="string">"******"</span></span><br><span class="line"><span class="keyword">as</span> table1;</span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> table1 <span class="keyword">limit</span> <span class="number">100</span> <span class="keyword">as</span> table2;</span><br><span class="line"></span><br><span class="line">save append table2 as delta.`dt1`;</span><br><span class="line"></span><br><span class="line"><span class="keyword">load</span> delta.<span class="string">`dt1`</span> <span class="keyword">as</span> table3;</span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> table3 <span class="keyword">as</span> table4;</span><br></pre></td></tr></table></figure><p><img src="//lwz9103.github.io/2021/03/22/mlsql-task-2/image-20210322151105057.png" alt="image-20210322151105057"></p><p><img src="//lwz9103.github.io/2021/03/22/mlsql-task-2/image-20210322151121200.png" alt="image-20210322151121200"></p></li><li><p>通过MLSQL mock一些Json格式数据，然后批量写入数据到Kafka中</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> jsonData=<span class="string">'''</span></span><br><span class="line"><span class="string">&#123; "id": 1, "name": "a", "age": 20 ,"gender":"f"&#125;</span></span><br><span class="line"><span class="string">&#123; "id": 2, "name": "b", "age": 25 ,"gender":"m"&#125;</span></span><br><span class="line"><span class="string">&#123; "id": 3, "name": "c", "age": 30 ,"gender":"f"&#125;</span></span><br><span class="line"><span class="string">&#123; "id": 4, "name": "d", "age": 35 ,"gender":"m"&#125;</span></span><br><span class="line"><span class="string">&#123; "id": 5, "name": "e", "age": 19 ,"gender":"f"&#125;</span></span><br><span class="line"><span class="string">'''</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">load</span> jsonStr.<span class="string">`jsonData`</span> <span class="keyword">as</span> table1;</span><br><span class="line"><span class="keyword">select</span> to_json(<span class="keyword">struct</span>(*)) <span class="keyword">as</span> <span class="keyword">value</span> <span class="keyword">from</span> table1 <span class="keyword">as</span> table2;</span><br><span class="line">save append table2 as kafka.`aaa` where </span><br><span class="line">kafka.bootstrap.servers="127.0.0.1:9092";</span><br></pre></td></tr></table></figure><p><img src="//lwz9103.github.io/2021/03/22/mlsql-task-2/image-20210322151201376.png" alt="image-20210322151201376"></p></li><li><p>(可选题） 写一个流程序参考<a href="http://docs.mlsql.tech/mlsql-stack/stream/" target="_blank" rel="noopener">MLSQL流编程</a>,消费前面写入到Kafka的数据</p><p>将数据写入到 delta 中，方便后续消费</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- the stream name, should be uniq.</span></span><br><span class="line"><span class="keyword">set</span> streamName=<span class="string">"kafkaExample"</span>;</span><br><span class="line"></span><br><span class="line">!kafkaTool registerSchema 2 records from "127.0.0.1:9092" aaa;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- convert table as stream source</span></span><br><span class="line"><span class="keyword">load</span> kafka.<span class="string">`aaa`</span> options </span><br><span class="line">kafka.bootstrap.servers=<span class="string">"127.0.0.1:9092"</span></span><br><span class="line"><span class="keyword">and</span> failOnDataLoss=<span class="string">"false"</span></span><br><span class="line"><span class="keyword">as</span> newkafkatable1;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- aggregation </span></span><br><span class="line"><span class="keyword">select</span> *  <span class="keyword">from</span> newkafkatable1</span><br><span class="line"><span class="keyword">as</span> table21;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- output the the result to console.</span></span><br><span class="line">save append table21  </span><br><span class="line">as rate.`/tmp/delta/aaa-0` </span><br><span class="line">options mode="Append"</span><br><span class="line">and idCols="id"</span><br><span class="line">and duration="5"</span><br><span class="line">and checkpointLocation="/tmp/s-cpl6";</span><br></pre></td></tr></table></figure><p><img src="//lwz9103.github.io/2021/03/22/mlsql-task-2/image-20210322151256008.png" alt="image-20210322151256008"></p><p>查看 delta 中的数据</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">load</span> delta.<span class="string">`/tmp/delta/aaa-0`</span> <span class="keyword">as</span> show_table1;</span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> show_table1 <span class="keyword">as</span> <span class="keyword">output</span>;</span><br></pre></td></tr></table></figure><p><img src="//lwz9103.github.io/2021/03/22/mlsql-task-2/image-20210322151326844.png" alt="image-20210322151326844"></p></li><li><p>在MLSQL中使用Scala完成一个UDF的演示使用例子</p><p>利用上方 delta 的数据，写一个分析年龄范围的函数</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">load</span> delta.<span class="string">`/tmp/delta/aaa-0`</span> <span class="keyword">as</span> show_table1;</span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> show_table1 <span class="keyword">as</span> table2;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">-- regist udf</span></span><br><span class="line">register ScriptUDF.`` as ageRangeFun where</span><br><span class="line">and lang="scala"</span><br><span class="line">and udfType="udf"</span><br><span class="line">and code='''</span><br><span class="line">def apply(a:Long)=&#123;</span><br><span class="line">   var ageRange: String = ""</span><br><span class="line">   if (a &lt; 20) &#123;</span><br><span class="line">     ageRange = "1-19"</span><br><span class="line">   &#125;</span><br><span class="line">   if (a &gt;= 20 &amp;&amp; a &lt; 30) &#123;</span><br><span class="line">     ageRange = "20-29"</span><br><span class="line">   &#125;</span><br><span class="line">   if (a &gt;= 30) &#123;</span><br><span class="line">     ageRange = "&gt;=30"</span><br><span class="line">   &#125;</span><br><span class="line">   ageRange</span><br><span class="line">&#125;</span><br><span class="line">''';</span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> *, ageRangeFun(age) <span class="keyword">from</span> table2 <span class="keyword">as</span> table3;</span><br></pre></td></tr></table></figure><p><img src="//lwz9103.github.io/2021/03/22/mlsql-task-2/image-20210322151359285.png" alt="image-20210322151359285"></p></li><li><p>离线安装一个excel插件 参考<a href="http://docs.mlsql.tech/mlsql-stack/plugin/offline_install.html" target="_blank" rel="noopener">离线安装插件</a>,并上传任意excel文件，然后读取显示出来。</p><p>设置好环境后，上传单列 excel 文件，写入代码</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">load</span> binaryFile.<span class="string">`/tmp/upload/report.xlsx`</span> <span class="keyword">as</span> excel_table;</span><br><span class="line"></span><br><span class="line"><span class="comment">--!python env "PYTHON_ENV=source activate dev";</span></span><br><span class="line">!python conf "schema=st(field(Index,long))";</span><br><span class="line">!python conf "runIn=driver";</span><br><span class="line">!python conf "dataMode=model";</span><br><span class="line"></span><br><span class="line">!ray on excel_table '''</span><br><span class="line">import io</span><br><span class="line">import ray</span><br><span class="line">from pyjava.api.mlsql import RayContext</span><br><span class="line">import pandas as pd</span><br><span class="line">ray_context = RayContext.connect(globals(),None)</span><br><span class="line"></span><br><span class="line">excel_file_binary_list = [item for item in RayContext.collect_from(ray_context.data_servers())]</span><br><span class="line"></span><br><span class="line">df = pd.read_excel(io.BytesIO(excel_file_binary_list[0]["content"]))</span><br><span class="line"></span><br><span class="line">context.build_result([row for row in df.to_dict('records')])</span><br><span class="line"></span><br><span class="line">''' named excel_data;</span><br></pre></td></tr></table></figure><p><img src="//lwz9103.github.io/2021/03/22/mlsql-task-2/image-20210322151434148.png" alt="image-20210322151434148"></p></li></ol><p>   <img src="//lwz9103.github.io/2021/03/22/mlsql-task-2/image-20210322151449501.png" alt="image-20210322151449501"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;任务2：学习-MLSQL-基本语言&quot;&gt;&lt;a href=&quot;#任务2：学习-MLSQL-基本语言&quot; class=&quot;headerlink&quot; title=&quot;任务2：学习 MLSQL 基本语言&quot;&gt;&lt;/a&gt;任务2：学习 MLSQL 基本语言&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;连
      
    
    </summary>
    
      <category term="MLSQL" scheme="https://lwz9103.github.io/categories/MLSQL/"/>
    
      <category term="MLSQL 入门学习任务" scheme="https://lwz9103.github.io/categories/MLSQL/MLSQL-%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E4%BB%BB%E5%8A%A1/"/>
    
    
  </entry>
  
  <entry>
    <title>mlsql-task-3</title>
    <link href="https://lwz9103.github.io/2021/03/21/mlsql-task-3/"/>
    <id>https://lwz9103.github.io/2021/03/21/mlsql-task-3/</id>
    <published>2021-03-21T12:52:30.000Z</published>
    <updated>2021-03-22T07:09:52.768Z</updated>
    
    <content type="html"><![CDATA[<h3 id="设置-MLSQL-环境依赖"><a href="#设置-MLSQL-环境依赖" class="headerlink" title="设置 MLSQL  环境依赖"></a>设置 MLSQL  环境依赖</h3><ol><li><p>检查本机 Python 版本</p><p><img src="//lwz9103.github.io/2021/03/21/mlsql-task-3/image-20210321211426235.png" alt="image-20210321211426235"></p></li><li><p>安装依赖</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">pip install Cython</span><br><span class="line">pip install pyarrow==0.10.0</span><br><span class="line">pip install ray==0.8.0</span><br><span class="line">pip install aiohttp psutil setproctitle grpcio pandas xlsxwriter</span><br><span class="line">pip install watchdog requests click uuid sfcli  pyjava</span><br></pre></td></tr></table></figure></li><li><p>本机启动 ray</p><p><img src="//lwz9103.github.io/2021/03/21/mlsql-task-3/image-20210321211638975.png" alt="image-20210321211638975"></p><p><img src="//lwz9103.github.io/2021/03/21/mlsql-task-3/image-20210321215259601.png" alt="image-20210321215259601"></p></li><li><p>验证代码执行</p><p><img src="//lwz9103.github.io/2021/03/21/mlsql-task-3/image-20210321215321048.png" alt="image-20210321215321048"></p><p><img src="//lwz9103.github.io/2021/03/21/mlsql-task-3/image-20210321215329927.png" alt="image-20210321215329927"></p></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;设置-MLSQL-环境依赖&quot;&gt;&lt;a href=&quot;#设置-MLSQL-环境依赖&quot; class=&quot;headerlink&quot; title=&quot;设置 MLSQL  环境依赖&quot;&gt;&lt;/a&gt;设置 MLSQL  环境依赖&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;检查本机 Python 版本&lt;
      
    
    </summary>
    
      <category term="MLSQL" scheme="https://lwz9103.github.io/categories/MLSQL/"/>
    
      <category term="MLSQL 入门学习任务" scheme="https://lwz9103.github.io/categories/MLSQL/MLSQL-%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E4%BB%BB%E5%8A%A1/"/>
    
    
  </entry>
  
  <entry>
    <title>开篇语</title>
    <link href="https://lwz9103.github.io/2019/08/21/first-post/"/>
    <id>https://lwz9103.github.io/2019/08/21/first-post/</id>
    <published>2019-08-20T17:34:10.000Z</published>
    <updated>2019-10-29T18:18:16.238Z</updated>
    
    <content type="html"><![CDATA[<h3 id="为什么开博客？"><a href="#为什么开博客？" class="headerlink" title="为什么开博客？"></a>为什么开博客？</h3><h4 id="知识管理"><a href="#知识管理" class="headerlink" title="知识管理"></a>知识管理</h4><p>何为知识管理，个人认为是对过去经历过的或未来可能面临到的各类问题的应对策略的总结，以便在碰到类似问题时高效的找到解决方案。那么，高效的<strong>存储和读取</strong>知识记录就应该是知识管理工具的必备特点。</p><p>之前有用有道云，onenote 做知识记录的习惯，但随着记录经验的增加，发现自己对知识记录有了更进一步的需求。之前只是需要<strong>知识的存储检索和同步</strong>，现在还需要<strong>简洁的记录方式</strong>，<strong>优雅的外观</strong>，同时不失<strong>强大的功能</strong>。</p><p>由于经常使用 github，所以在页面编辑方式上首选 <strong>markdown</strong>，外观显示上采用 <strong>github pages + hexo + next</strong>，编辑工具使用 <strong>typora</strong>。由于 hexo 和 next 有众多开发者贡献插件，各类功能也能得到很好的保障。</p><a id="more"></a><h4 id="大脑瘦身"><a href="#大脑瘦身" class="headerlink" title="大脑瘦身"></a>大脑瘦身</h4><p>之前经常看一些技术文章，看的过程中觉得理解了。碰到问题的时候，经常会有种感觉，仿佛哪里见过，但就是说不清楚是哪了，怎么解决的。去各类知识平台搜索自己的浏览记录，却发现已经找不到任何痕迹了。这类知识，早被大脑<strong>垃圾回收了</strong>，也没有持久化，这就基本相当于浪费了阅读这段知识所花的时间。要想让这些知识能重回到大脑里，就得有引用指向这些知识。这个引用的产生可以是从外部知识存储中加载到大脑中，但这<strong>存在一定的时限</strong>，所以有可能需要<strong>定时的加载</strong>。另外，日常生活&amp;工作正常进行所需的知识会自然而然的保存到大脑的 context 中，这块知识由于经常被引用，所以能避免被大脑当成垃圾回收掉。</p><p>由于大脑存储容量及性能有限，装载的太满容易卡机（垃圾回收频繁，大脑得释放一些内存）。所以对于一些占用空间大，使用频率低的知识可以做外部知识链接，比如各类不常用系统的搭建流程（jenkins，sonar etc.）。外部知识链接即知识存储在外部系统（笔记本），但是脑子里存了一份知识关键字到外部存储位置的链接关系。这里知识的关键字存在不同的详细程度，比如 jenkins 相关的知识、jenkins 搭建相关的流程、jenkins 搭建中构建节点的配置，其详细程度是依次递增的。对一个知识认识的详细程度越高，搜索起来效率也越高（搜索关键字准确），trade off 是需要更多的时间和空间来加载这些知识链接。</p><h4 id="系统思考"><a href="#系统思考" class="headerlink" title="系统思考"></a>系统思考</h4><p>写作是系统化思考知识最有效的方式。平时，可能看到或者听来的知识，可能很少来得及深入思考，这就导致较复杂的一些知识没法有效的转换成自己的经验。但是，在写作总结知识的过程中，脑子里会抛出一系列疑问和假设，对这些疑问和假设一一思考过后，就会更加深刻的理解知识其中的含义，写出来的东西也更能让未来的你或者别人看懂。</p><h3 id="写博客需要注意的点"><a href="#写博客需要注意的点" class="headerlink" title="写博客需要注意的点"></a>写博客需要注意的点</h3><h4 id="由浅入深，适可而止"><a href="#由浅入深，适可而止" class="headerlink" title="由浅入深，适可而止"></a>由浅入深，适可而止</h4><p>知识的整理存档并不是一件轻松的事情，所以需要衡量效用和耗时。我把对知识的理解归为三个层次。第一层次，能够正确使用知识暴露的最外层接口。第二层次，理解知识内在的工作逻辑，在出现异常状况时，能够快速找到 Root Cause。第三层级，深刻理解知识运用的场景，明白其潜在的缺陷，并且能有自己的见解去改善它。</p><p>大部分时候，我们只需要掌握第一层次，就能基本应付工作和生活了。所以在去深入了解一门知识前，都先考虑考虑是否值得花这些时间。</p><h4 id="从源头收集资料"><a href="#从源头收集资料" class="headerlink" title="从源头收集资料"></a>从源头收集资料</h4><p>从源头收集资料，这样可以避免多次转手带来的偏差。参考的优先级为：</p><p> <code>官网/国际期刊论文书籍 --&gt; 卓有成就的专家博客 --&gt; 较专业的知识分享网站 --&gt; google 搜索 --&gt; bing --&gt; 某度</code></p><h4 id="经过验证"><a href="#经过验证" class="headerlink" title="经过验证"></a>经过验证</h4><p>知识存档前需要验证其准确性。有些知识可能会因为来源问题，时间问题（版本）导致不可被验证。这类需要被剔除，因为它已经没用了。</p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;为什么开博客？&quot;&gt;&lt;a href=&quot;#为什么开博客？&quot; class=&quot;headerlink&quot; title=&quot;为什么开博客？&quot;&gt;&lt;/a&gt;为什么开博客？&lt;/h3&gt;&lt;h4 id=&quot;知识管理&quot;&gt;&lt;a href=&quot;#知识管理&quot; class=&quot;headerlink&quot; title=&quot;知识管理&quot;&gt;&lt;/a&gt;知识管理&lt;/h4&gt;&lt;p&gt;何为知识管理，个人认为是对过去经历过的或未来可能面临到的各类问题的应对策略的总结，以便在碰到类似问题时高效的找到解决方案。那么，高效的&lt;strong&gt;存储和读取&lt;/strong&gt;知识记录就应该是知识管理工具的必备特点。&lt;/p&gt;
&lt;p&gt;之前有用有道云，onenote 做知识记录的习惯，但随着记录经验的增加，发现自己对知识记录有了更进一步的需求。之前只是需要&lt;strong&gt;知识的存储检索和同步&lt;/strong&gt;，现在还需要&lt;strong&gt;简洁的记录方式&lt;/strong&gt;，&lt;strong&gt;优雅的外观&lt;/strong&gt;，同时不失&lt;strong&gt;强大的功能&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;由于经常使用 github，所以在页面编辑方式上首选 &lt;strong&gt;markdown&lt;/strong&gt;，外观显示上采用 &lt;strong&gt;github pages + hexo + next&lt;/strong&gt;，编辑工具使用 &lt;strong&gt;typora&lt;/strong&gt;。由于 hexo 和 next 有众多开发者贡献插件，各类功能也能得到很好的保障。&lt;/p&gt;
    
    </summary>
    
      <category term="杂谈" scheme="https://lwz9103.github.io/categories/%E6%9D%82%E8%B0%88/"/>
    
    
      <category term="扯淡" scheme="https://lwz9103.github.io/tags/%E6%89%AF%E6%B7%A1/"/>
    
  </entry>
  
</feed>
